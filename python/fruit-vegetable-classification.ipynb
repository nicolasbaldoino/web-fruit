{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4402ccb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-02T04:12:57.715920Z",
     "iopub.status.busy": "2021-11-02T04:12:57.714298Z",
     "iopub.status.idle": "2021-11-02T04:12:59.058276Z",
     "shell.execute_reply": "2021-11-02T04:12:59.059163Z",
     "shell.execute_reply.started": "2021-11-02T04:08:50.319628Z"
    },
    "papermill": {
     "duration": 1.370405,
     "end_time": "2021-11-02T04:12:59.059493",
     "exception": false,
     "start_time": "2021-11-02T04:12:57.689088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import os\n",
    "import numpy as np  # Álgebra linear\n",
    "import pandas as pd  # Processamento de dados e leitura de arquivos CSV\n",
    "\n",
    "# Exibição dos arquivos disponíveis no diretório de entrada\n",
    "input_dir = '/kaggle/input'\n",
    "for dirname, _, filenames in os.walk(input_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Observações:\n",
    "# - Você pode gravar até 20GB no diretório atual (/kaggle/working/) e os arquivos serão preservados\n",
    "#   ao criar uma versão usando \"Save & Run All\".\n",
    "# - Arquivos temporários podem ser gravados em /kaggle/temp/, mas não serão salvos fora da sessão atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80f008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-02T04:12:59.131000Z",
     "iopub.status.busy": "2021-11-02T04:12:59.129810Z",
     "iopub.status.idle": "2021-11-02T04:13:04.578664Z",
     "shell.execute_reply": "2021-11-02T04:13:04.577747Z",
     "shell.execute_reply.started": "2021-11-02T04:10:42.022652Z"
    },
    "papermill": {
     "duration": 5.486991,
     "end_time": "2021-11-02T04:13:04.578852",
     "exception": false,
     "start_time": "2021-11-02T04:12:59.091861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importações de bibliotecas\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Exibe a versão do TensorFlow\n",
    "print(tf.__version__)\n",
    "\n",
    "# Configuração dos caminhos para os conjuntos de dados\n",
    "train_dir = Path('../input/fruit-and-vegetable-image-recognition/train')\n",
    "test_dir = Path('../input/fruit-and-vegetable-image-recognition/test')\n",
    "val_dir = Path('../input/fruit-and-vegetable-image-recognition/validation')\n",
    "\n",
    "# Listagem de arquivos\n",
    "train_filepaths = list(train_dir.glob(r'**/*.jpg'))\n",
    "test_filepaths = list(test_dir.glob(r'**/*.jpg'))\n",
    "val_filepaths = list(val_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "# Função para processamento de imagens\n",
    "def image_processing(filepath):\n",
    "    \"\"\"\n",
    "    Cria um DataFrame contendo os caminhos dos arquivos e os rótulos das imagens.\n",
    "    \"\"\"\n",
    "    labels = [str(filepath[i]).split(\"/\")[-2] for i in range(len(filepath))]\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatena caminhos e rótulos e embaralha o DataFrame\n",
    "    df = pd.concat([filepath, labels], axis=1).sample(frac=1).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Criação dos DataFrames de treino, teste e validação\n",
    "train_df = image_processing(train_filepaths)\n",
    "test_df = image_processing(test_filepaths)\n",
    "val_df = image_processing(val_filepaths)\n",
    "\n",
    "# Informações sobre o conjunto de treino\n",
    "print('-- Conjunto de Treino --\\n')\n",
    "print(f'Número de imagens: {train_df.shape[0]}\\n')\n",
    "print(f'Número de rótulos únicos: {len(train_df.Label.unique())}\\n')\n",
    "print(f'Rótulos: {train_df.Label.unique()}')\n",
    "\n",
    "# Exibe as primeiras 5 linhas do DataFrame de treino\n",
    "print(train_df.head(5))\n",
    "\n",
    "# Visualização de amostras do conjunto de dados\n",
    "df_unique = train_df.drop_duplicates(subset=[\"Label\"]).reset_index()\n",
    "fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(df_unique.Filepath[i]))\n",
    "    ax.set_title(df_unique.Label[i], fontsize=12)\n",
    "\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Geradores de imagens com pré-processamento\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "# Configuração dos geradores para treino, validação e teste\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Configuração do modelo pré-treinado MobileNetV2\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# Construção do modelo\n",
    "inputs = pretrained_model.input\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(36, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predição nos dados de teste\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "# Mapeamento dos rótulos\n",
    "labels = {v: k for k, v in train_images.class_indices.items()}\n",
    "pred_labels = [labels[k] for k in pred]\n",
    "\n",
    "# Função para predição em uma imagem individual\n",
    "def output(location):\n",
    "    \"\"\"\n",
    "    Faz a predição para uma imagem fornecida.\n",
    "    \"\"\"\n",
    "    img = load_img(location, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img) / 255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    answer = model.predict(img)\n",
    "    y_class = answer.argmax(axis=-1)\n",
    "    res = labels[int(y_class[0])]\n",
    "    return res\n",
    "\n",
    "# Teste com uma imagem de exemplo\n",
    "img = output('../input/fruit-and-vegetable-image-recognition/test/cabbage/Image_1.jpg')\n",
    "print(img)\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1124.050414,
   "end_time": "2021-11-02T04:31:32.927130",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-02T04:12:48.876716",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
